js_string <- 'alert("SOMETHING");'
js_string <- sub("SOMETHING",my_date_check_test,js_string)
session$sendCustomMessage(type='jsCode', list(value = js_string))
}
})
})
my_data <- reactive({
if(input$run==0){return()}
isolate({
input$run
if(input$my_slider >= 100)
{
# Alert below will trigger if you adjusted the date but slider is still 100
my_slider_check_test <- "Slider is still over 100"
js_string <- 'alert("SOMETHING");'
js_string <- sub("SOMETHING",my_slider_check_test,js_string)
session$sendCustomMessage(type='jsCode', list(value = js_string))
}
if(input$my_slider < 100)
{
iris[1:input$my_slider,]
}
})
})
output$tbl = DT::renderDataTable(my_data(), options = list(lengthChange = FALSE))
}
shinyApp(ui = ui, server = server)
require(stringi)
require(shiny)
# write text file with standard newline characters
str <- 'These are words\nwith newline characters\n\nthat do not render.'
write(x = str, file = 'Data.txt')
ui <- fluidPage(
h4('Reading raw text from file:'),
textOutput('textWithNewlines'), # text with newline characters output
h4('Converting text to list of paragraph tags'),
uiOutput('textWithHTML') # ui output as a list of HTML p() tags
)
server <- function(input,output){
output$textWithNewlines <- renderText({
rawText <- readLines('Data.txt')
return(rawText)
})
### SOLUTION ###
output$textWithHTML <- renderUI({
rawText <- readLines('Data.txt') # get raw text
# split the text into a list of character vectors
#   Each element in the list contains one line
splitText <- stringi::stri_split(str = rawText, regex = '\\n')
# wrap a paragraph tag around each element in the list
replacedText <- lapply(splitText, p)
return(replacedText)
})
}
shinyApp(ui=ui, server=server)
#=====================================================================================CR
# 170609 MG : Pinging WEB site
#=====================================================================================CR
havingIP <- function() {
if (.Platform$OS.type == "windows") {
ipmessage <- system("ipconfig", intern = TRUE)
} else {
ipmessage <- system("/sbin/ifconfig", intern = TRUE)
}
validIP <- "((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)[.]){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)"
any(grep(validIP, ipmessage))
}
#=====================================================================================CR
### Function Load.Packages (170420)
#=====================================================================================CR
Load.Packages <- function(list.Packages, verbose = FALSE) {
# This function install packages if needed and load them
# list.Packages                 vector of names of the packages to load
# verbose                       logical default FALSE, return info message about error and installed packages
# dependence                    havingIP()
cat("-----------------------------------------------------------------------------------\n")
if(verbose) cat("[Load.Packages] INFO CHECK Installed packages and Toolbox to run the script\n")
#
# checking if internet is available and CRAN can be accessed
isInternet <- havingIP()
if(verbose) if(isInternet) cat("[Load.Packages] Info: internet is available\n") else cat("[Load.Packages] Info: internet is not available\n")
for(i in list.Packages) {
if(i %in% rownames(installed.packages()) == FALSE) {
if(verbose) cat(sprintf("[Load.Packages] INFO Installing %s", i), sep = "\n")
if(isInternet) install.packages(i) else stop(cat(paste0("[Load.Packages] ERROR: missing internet to install package ", i), sep = "\n"))
} else {
if(verbose) cat(sprintf("[Load.Packages] INFO Package %s already installed",i), sep = "\n")
}
do.call("library", as.list(i))
if(verbose) cat(sprintf("[Load.Packages] INFO Package %s loaded",i), sep = "\n")
}
# List of loaded packages
if(verbose) cat("[Load.Packages] INFO List of installed packages\n")
if(verbose) print(search(), quote = FALSE)
cat("-----------------------------------------------------------------------------------\n")
}
list.Packages <- c( "xlsx", "readxl","XLConnect","stats","openair", "lubridate", "rChoiceDialogs")
Load.Packages(list.Packages,verbose = TRUE)
# load data
file.xlsx <- rchoose.files(caption = "Choose excel datafile",
filters = rbind(c("xlsx files (*.xlsx)","*.xlsx"),
c("xls files (*.xls)","*.xls")
),
index = 1
)
file.xlsx
# Data <- xlsx::read.xlsx(file = choose.files(filters = c("xlsx","xls")),
#                   sheetIndex = 1,
#                   startRow = 21,
#                   as.data.frame = TRUE,
#                   header = TRUE,
#                   stringsAsFactors=FALSE
#                   )
Data <- data.frame(readxl::read_xlsx(path  = file.xlsx,
sheet = 1,
skip  = 20),
stringsAsFactors = FALSE
)
View(Data)
# read_xlsx as converted "Begintijd" and "Eindtijd" in POSIX with time zone UTC
# Howwever, it seems that the real time zone is Europe/Amsterdam
lubridate::tz(Data$Begintijd) <- "Etc/GMT-1" #"Europe/Amsterdam"
# Converting data to proper format
str(Data)
Data$Begintijd[1]
Convert.numeric    <- names(Data)[grep(pattern = "Waarden", x = names(Data))]
Convert.character  <- names(Data)[!(names(Data) %in% Convert.numeric | names(Data) %in% c("Begintijd","Eindtijd"))]
Names.Pollutants   <- c("NO", "NO2","O3")
New.Names <- as.data.frame(cbind(Convert.numeric,Names.Pollutants), stringsAsFactors = FALSE)
for(i in names(Data)){
if(i %in% Convert.numeric){
# Converting to numeric
if(class(Data[,i]) %in% c("factor", "character")) Data[,i] <- as.numeric(Data[,i])
# Setting pollutant names
names(Data)[names(Data)==i] <- New.Names[New.Names$Convert.numeric == i, "Names.Pollutants"]
} else {
if(i %in% Convert.character){
if(class(Data[,i]) == "factor") Data[,i] <- as.character(Data[,i])
}
}
}
str(Data)
# set data to NAs, quality control
if(length(which(Data[,"Status.Meetwaarden"]    != "0x0")) > 0) Data$NO[which(Data[ ,"Status.Meetwaarden"]    != "0x0")] <- NA
if(length(which(Data[,"Status.Meetwaarden__1"] != "0x0")) > 0) Data$NO2[which(Data[,"Status.Meetwaarden__1"] != "0x0")] <- NA
if(length(which(Data[,"Status.Meetwaarden__2"] != "0x0")) > 0) Data$O3[which(Data[ ,"Status.Meetwaarden__2"] != "0x0")] <- NA
# Removing rows with NA
if(length(
which(
rowSums(
is.na(Data[,New.Names$Names.Pollutants])
) == length(New.Names$Names.Pollutants)
)
) > 0
) Data <- Data[-which(rowSums(is.na(Data[,New.Names$Names.Pollutants])) == length(New.Names$Names.Pollutants)), ]
# Selecting date for plotting
# Between Begintijd and Eindtijd, it is not clear which one to use as "date". I use Eindtijd the end of the average periods
Data.Sort <- Data[Data$Eindtijd < min(Data$Eindtijd, na.rm = TRUE) + 10 * 24 *60*60,]
names(Data.Sort)[names(Data.Sort) == "Eindtijd"] <- "date"
timePlot(Data.Sort,
pollutant = Names.Pollutants,
y.relation = "free")
# Read CO data
default.search = paste(getwd(),"/*.dat",sep="")
file.CO <- choose.files(default.search, filters = Filters[c("date","xls")], caption = "Choose CO *.dat datafile")
file.CO <- rchoose.files(caption = "Choose CO *.dat datafile",
filters = rbind(c("dat files (*.dat)","*.dat"),
c("xlsx files (*.xlsx)","*.xlsx"),
c("xls files (*.xls)","*.xls")
),
index = 1
)
file.CO
Data.CO <- read.csv(file = file.CO,
header = TRUE,
sep = "",
dec = ".",
skip = 5,
stringsAsFactors = FALSE
)
str(Data.CO)
# Converting "Time" and "Date" to POSIXct "date" with TimeZone CEST as said by Jan
Data.CO$date <- as.POSIXct(paste0(Data.CO$Date, " ", Data.CO$Time), format("%m-%d-%y %H:%M"), tz = "Europe/Amsterdam")
str(Data.CO)
# Plotting and discarding autoZero
Data.Sort.CO <- Data.CO[Data.CO$date < min(Data.CO$date, na.rm = TRUE) + 0.25 * 24 *60*60,]
timePlot(Data.Sort.CO, pollutant = "co")
# Discarding 12 minutes every 2 hours
min.date <- lubridate::floor_date(x = min(Data.CO$date, na.rm = TRUE), unit = "2 hours")
every.2hours <- seq(from=min.date, by = 120 *60 , to = max(Data.CO$date, na.rm = TRUE))
# Although the auto zero last for 12 minutes, I observed that 14 minutes are necessary until the analyser reach a stable concentration level
QC.CO <- data.frame(start = every.2hours, end =  every.2hours + 14 * 60) # 14 represents the number of minutes to discard for every autozero
for (i in seq(nrow(QC.CO))) {
# Index of auto-zero
QC.Index <- which(Data.CO$date>= QC.CO$start[i] & Data.CO$date < QC.CO$end[i])
if(length(QC.Index) > 0) Data.CO$co[QC.Index] <- NA
}
# Plotting
for(i in seq(length(unique(day(Data.CO$date))))){
Data.Sort.CO <- Data.CO[Data.CO$date >= min(Data.CO$date, na.rm = TRUE) + (i-1) * 24 *60 *60 & Data.CO$date < min(Data.CO$date, na.rm = TRUE)  + i * 24 *60*60,]
if(nrow(Data.Sort.CO) > 0) timePlot(Data.Sort.CO, pollutant = "co", main = paste0("day ", i))
}
# Merging CO with other pollutants
# Renaming Eindtijd as "date"
# Between Begintijd and Eindtijd, it is not clear which one to use as "date". I use Eindtijd the end of the average periods
names(Data)[names(Data) == "Eindtijd"] <- "date"
Final.data <- merge(x = Data[, c("date",Names.Pollutants)], y = Data.CO[,c("date","co")], by = "date", all = TRUE)
str(Final.data)
# plotting
for(i in seq(length(unique(day(Final.data$date))))){
Data.Sort <- Final.data[Final.data$date >= min(Final.data$date, na.rm = TRUE) + (i-1) * 24 *60 *60 & Final.data$date < min(Final.data$date, na.rm = TRUE)  + i * 24 *60*60,]
if(nrow(Data.Sort) > 0) timePlot(Data.Sort,
pollutant = c(Names.Pollutants,"co"),
main =unique(date(Final.data$date))[i],
y.relation = "free")
}
timePlot(Final.data,
pollutant = c(Names.Pollutants,"co"),
date.pad = TRUE,
y.relation = "free")
# saving file
# choose directory where to save the csv file
DIR <- choose.dir()
# saving file
# choose directory where to save the csv file
# DIR <- choose.dir()
DIR <- rchoose.dir(default = getwd(), caption = "Select Directory for saving refrence value file")
DIR
# load packages ----
require(openair)
require(plyr)
require(rChoiceDialogs)
require(plyr)
require(reshape2)
# Selecting Directory wher are the list files ----
DIR <- rchoose.dir(caption = "select directory to save list of urls")
# List of Station URL lists ----
Liste <- list.files(path = DIR, pattern = glob2rx(pattern = "list*.csv"))
for(i in Liste){
pollutant.name <- gsub(pattern = ".csv", replacement = "", x = i)
pollutant.name <- gsub(pattern = "list", replacement = "", x = pollutant.name)
# assign the list of URLs for each pollutant
# they are duplicated in the list of URLs, use function unique
assign(x = paste0(pollutant.name,".URL"),
value = read.csv(file.path(DIR,i),
header = FALSE,
stringsAsFactors = FALSE)
)
# Are there dulicated
if(any(duplicated(get(paste0(pollutant.name,".URL"))))){
cat(paste0("The liste of URLs for ", pollutant.name, " includes ", length(which(duplicated(get(paste0(pollutant.name,".URL"))))),
" duplicated URLs out of ", nrow(get(paste0(pollutant.name,".URL"))), " URLs that are discarded.\n"))
cat("List of duplicated URLs:\n")
get(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),]
# Saving and dicarding duplicated URLs
write.csv(x = get(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),],
file = file.path(DIR,paste0("Duplicated_",i)))
assign(x = paste0(pollutant.name,".URL"),
value = unique(get(paste0(pollutant.name,".URL")))
)
}
}
print(get(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),], quote = F)
pollutant.name
et(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),]
get(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),]
for(i in Liste){
pollutant.name <- gsub(pattern = ".csv", replacement = "", x = i)
pollutant.name <- gsub(pattern = "list", replacement = "", x = pollutant.name)
# assign the list of URLs for each pollutant
# they are duplicated in the list of URLs, use function unique
assign(x = paste0(pollutant.name,".URL"),
value = read.csv(file.path(DIR,i),
header = FALSE,
stringsAsFactors = FALSE)
)
# Are there dulicated
if(any(duplicated(get(paste0(pollutant.name,".URL"))))){
cat(paste0("The liste of URLs for ", pollutant.name, " includes ", length(which(duplicated(get(paste0(pollutant.name,".URL"))))),
" duplicated URLs out of ", nrow(get(paste0(pollutant.name,".URL"))), " URLs that are discarded.\n"))
cat("List of duplicated URLs:\n")
print(get(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),], quote = F)
# Saving and dicarding duplicated URLs
write.csv(x = get(paste0(pollutant.name,".URL"))[which(duplicated(get(paste0(pollutant.name,".URL")))),],
file = file.path(DIR,paste0("Duplicated_",i)))
assign(x = paste0(pollutant.name,".URL"),
value = unique(get(paste0(pollutant.name,".URL")))
)
}
}
# Metadata of all stations ----
Metadata <- read.csv(file =  file.path(DIR, "Station_MetaData.csv"),
sep = ",",
header = TRUE,
stringsAsFactors = FALSE)
View(Metadata[Metadata[,1] == "Portugal",])
Pollutant.of.Interest <- unique(Metadata$Pollutant)[c(1,2,6,9,12,14,15,16,17,18,19,31,33,36,96,118,119,128, 131,132,149,278,279, 281, 320)]
Pollutant.of.Interest
#  [1] Sulphur dioxide (air)                   Toluene (air)                           Particulate matter < 10 µm (aerosol)   Ozone (air)
#  [5] Organic carbon in PM2.5 (aerosol)       Particulate matter < 2.5 µm (aerosol)  Carbon monoxide (air)                   Nitrogen oxides (air)
#  [9] Nitrogen dioxide (air)                  Nitrogen monoxide (air)                 Benzene (air)                           1.3 Butadiene (air)
# [13] m,p-Xylene (air)                        o-Xylene (air)                          Total volatile organic compounds (air)  Carbon dioxide (air)
# [17] Methane (air)                           chloride in PM10 (aerosol)              Nitrate in PM10 (aerosol)               sulphate in PM10 (aerosol)
# [21] Total non-methane hydrocarbons (air)    Particulate matter < 1 µm (aerosol)    Polyaromatic hydrocarbons (air+aerosol) Total ammonium (air+aerosol)
# [25] m-Xylene (air)
Metadata <- Metadata[Metadata$Pollutant %in% c("Sulphur dioxide (air)",
"Carbon monoxide (air)",
"Particulate matter < 10 µm (aerosol)",
"Nitrogen monoxide (air)",
"Nitrogen dioxide (air)",
"Ozone (air)"), c(1,8,9,10)]
# Let's extract the number of stations and total period of time
table(Metadata)
summarise(Metadata,
Pollutant.Nb = count(Pollutant)
)
# Combine with ddply to do that for each separate countries
ddply(Metadata, names(Metadata)[1], summarise,
Pollutant = count(Pollutant))
dcast(Metadata, StationType ~ Pollutant, count)
j="SO2"
cat(paste0("Pollutant: ",j,"\n"))
file.exists(file.path(DIR, paste0("Table_",j, ".csv")))
assign(paste0("Table_",j),
value = read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
)
read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
file.path(DIR, paste0("Table_",j, ".csv"))
Table_SO2 <- read.csv("/media/sf_Box_Sync/AirBase/Table_SO2.csv", encoding="LATIN1", comment.char="#", stringsAsFactors=FALSE)
View(Table_SO2)
read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
encoding = "latin1"
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
encoding = "latin1",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
encoding="latin1",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
Sys.info()
Table_SO2 <- read.csv("/media/sf_Box_Sync/AirBase/Table_SO2.csv", encoding="UTF16", comment.char="#")
View(Table_SO2)
read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
encoding="utf-16",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
i
i=1
read.csv(file = get(paste0(j,"_hour.URL"))[i,], header = TRUE, skipNul = TRUE, stringsAsFactors = FALSE)
j
get(paste0(j,"_hour.URL"))[i,]
read.csv(file = get(paste0(j,"_hour.URL"))[i,],
header = TRUE,
skipNul = TRUE,
stringsAsFactors = FALSE)
read.csv(file = file.path(DIR, paste0("Table_",j, ".csv")),
encoding="unknown",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv")), encoding="unknown"),
encoding="unknown",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv")), encoding="unknown"),
#encoding="unknown",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv"))),
#encoding="unknown",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv"))),
encoding="unknown",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv"))),
encoding="ANSI",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv"))),
encoding="ISO-8859",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv"))),
encoding="ISO-8859-1",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
read.csv(file(file.path(DIR, paste0("Table_",j, ".csv"))),
encoding="windows-1252",
header = TRUE,
sep =  ",",
stringsAsFactors = FALSE)
0.903^2
0.92^2
22672+697+1802
0.951^2
0.92^2
library(shiny)
runApp(list(
ui = pageWithSidebar(
headerPanel("'Reset inputs' button example"),
sidebarPanel(
shinyjs::useShinyjs(),
id = "side-panel",
numericInput("mynumber", "Enter a number", 20),
textInput("mytext", "Enter a text", "test"),
tags$hr(),
actionButton("reset_input", "Reset inputs")
),
mainPanel(
h4("Summary"),
verbatimTextOutput("summary")
)
),
server = function(input, output, session) {
output$summary <- renderText({
return(paste(input$mytext, input$mynumber))
})
observeEvent(input$reset_input, {
shinyjs::reset("side-panel")
})
}
))
shiny::runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
shiny::runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
runApp('/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny')
2393+046*50+25*908
2393+046*50+25*2.39
2384+50-1.23*25+0.0893*25^2
(2460-(2384-(-1.23*25+0.893*25^2)))/0.46
2384+0.46*50-1.23*25+0.0893*25^2
(2432 - ( 2384 + -1.23*25 + 0.893*25^2))/0.46
2384 + 0.46 * 50 - 1.228 * 25 + 0.0893*25^2
2432 - (2384 + -1.228*25 + 0.893 * 25 ^ 2)
2432 - (2384 + -1.228*25 + 0.0893 * 25 ^ 2)
(2432 - (2384 + -1.228*25 + 0.0893 * 25 ^ 2)) / 0. 468
(2432 - (2384 + -1.228*25 + 0.0893 * 25 ^ 2)) / 0. 468
(2432 - (2384 + -1.228*25 + 0.0893 * 25 ^ 2)) /0.468
-1.228*25 + 0.0893 * 25 ^ 2
-1.228*24.947 + 0.0893 * 24.97 ^ 2
-1.22830852 * 24.947484 + 0.08926309 * 24.947484 ^ 2
(2222.167 - 2384.02459 + 24.92))/0.46798
(2222.167 - (2384.02459 + 24.92))/0.46798
(2399.612 - (2384.02459 + 44.53824))/0.46798
2384.02459+0.46798*50 + -1.22830852 * 30.24252 + 0.08926309 * 915.10827
2384.02459 + 0.46798 * 20 + -1.22830852 * 30.24252 + 0.08926309 * 915.10827
2384.02459 + 0.46798 * 0 + -1.22830852 * 30.24252 + 0.08926309 * 915.10827
setwd("~/")
setwd("/media/sf_Box_Sync/AirSensEUR/Fieldtests/Shiny/NL_05min/Models")
Model.i         <- readRDS(file = file.path(file.choose))
Model.i         <- readRDS(file = file.path(file.choose()))
Model.i
plot(Model.i$x, Model.i$fitted.values)
Model.i$fitted.values
length(Model.i$fitted.values)
length(Model.i$s)
length(Model.i$x)
View(Final.data)
plot(Model.i$model$x, Model.i$fitted.values)
View(Model.i$model)
plot(Model.i$model$y, coef(Model.i)[1] + coef(Model.i[2] * Model.i$model$x + coef(Model.i)[3] * Model.i$model$`I(Temperature^1)` + coef(Model.i)[4] * Model.i$model$`I(Temperature^2)`))
plot(Model.i$model$y, coef(Model.i)[1] + coef(Model.i)[2] * Model.i$model$x + coef(Model.i)[3] * Model.i$model$`I(Temperature^1)` + coef(Model.i)[4] * Model.i$model$`I(Temperature^2)`))
plot(Model.i$model$y, Model.i$fitted.values)
Model.i$residuals
NO <- (y - (coef(Model.i)[1] + coef(Model.i)[1] * Model.i$model$x + coef(Model.i)[3] * Model.i$model$`I(Temperature^1)` + coef(Model.i)[4] * Model.i$model$`I(Temperature^2)`)
)
NO <- (Model.i$model$y - (coef(Model.i)[1] + coef(Model.i)[1] * Model.i$model$x + coef(Model.i)[3] * Model.i$model$`I(Temperature^1)` + coef(Model.i)[4] * Model.i$model$`I(Temperature^2)`))
NO <- (Model.i$model$y - (coef(Model.i)[1] + coef(Model.i)[3] * Model.i$model$`I(Temperature^1)` + coef(Model.i)[4] * Model.i$model$`I(Temperature^2)`))/coef(Model.i)[2]
plot(Model.i$model$x, NO)
grid(NULL,NULL)
Matrice <- matrix(Model.i$model[3:4])
Matrice
Matrice <- Model.i$model[3:4]
Matrice
Matrice %*% coef(Model.i)[3:4]
as.matrix(Matrice %*%) coef(Model.i)[3:4]
as.matrix(Matrice) %*% coef(Model.i)[3:4]
M.Cov <- as.matrix(Matrice) %*% coef(Model.i)[3:4]
NO <- (Model.i$model$y - (coef(Model.i)[1] + M.Cov))/coef(Model.i)[2]
plot(Model.i$model$x, NO)
NO <- as.vector((Model.i$model$y - (coef(Model.i)[1] + M.Cov))/coef(Model.i)[2])
plot(Model.i$model$x, NO)
cor(Model.i$model$x, NO)
cor(Model.i$model$x, NO)^2
